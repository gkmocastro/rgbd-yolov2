{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BadPixelMetric:\n",
    "    def __init__(self, threshold=1.25, depth_cap=10):\n",
    "        self.__threshold = threshold\n",
    "        self.__depth_cap = depth_cap\n",
    "\n",
    "    def compute_scale_and_shift(self, prediction, target, mask):\n",
    "        # system matrix: A = [[a_00, a_01], [a_10, a_11]]\n",
    "        a_00 = torch.sum(mask * prediction * prediction, (1, 2))\n",
    "        a_01 = torch.sum(mask * prediction, (1, 2))\n",
    "        a_11 = torch.sum(mask, (1, 2))\n",
    "\n",
    "        # right hand side: b = [b_0, b_1]\n",
    "        b_0 = torch.sum(mask * prediction * target, (1, 2))\n",
    "        b_1 = torch.sum(mask * target, (1, 2))\n",
    "\n",
    "        # solution: x = A^-1 . b = [[a_11, -a_01], [-a_10, a_00]] / (a_00 * a_11 - a_01 * a_10) . b\n",
    "        x_0 = torch.zeros_like(b_0)\n",
    "        x_1 = torch.zeros_like(b_1)\n",
    "\n",
    "        det = a_00 * a_11 - a_01 * a_01\n",
    "        # A needs to be a positive definite matrix.\n",
    "        valid = det > 0\n",
    "\n",
    "        x_0[valid] = (a_11[valid] * b_0[valid] - a_01[valid] * b_1[valid]) / det[valid]\n",
    "        x_1[valid] = (-a_01[valid] * b_0[valid] + a_00[valid] * b_1[valid]) / det[valid]\n",
    "\n",
    "        return x_0, x_1\n",
    "\n",
    "    def __call__(self, prediction, target, mask):\n",
    "        # transform predicted disparity to aligned depth\n",
    "        target_disparity = torch.zeros_like(target)\n",
    "        target_disparity[mask == 1] = 1.0 / target[mask == 1]\n",
    "\n",
    "        scale, shift = self.compute_scale_and_shift(prediction, target_disparity, mask)\n",
    "        prediction_aligned = scale.view(-1, 1, 1) * prediction + shift.view(-1, 1, 1)\n",
    "\n",
    "        disparity_cap = 1.0 / self.__depth_cap\n",
    "        prediction_aligned[prediction_aligned < disparity_cap] = disparity_cap\n",
    "\n",
    "        prediciton_depth = 1.0 / prediction_aligned\n",
    "\n",
    "        # bad pixel\n",
    "        err = torch.zeros_like(prediciton_depth, dtype=torch.float)\n",
    "\n",
    "        err[mask == 1] = torch.max(\n",
    "            prediciton_depth[mask == 1] / target[mask == 1],\n",
    "            target[mask == 1] / prediciton_depth[mask == 1],\n",
    "        )\n",
    "\n",
    "        err[mask == 1] = (err[mask == 1] > self.__threshold).float()\n",
    "\n",
    "        p = torch.sum(err, (1, 2)) / torch.sum(mask, (1, 2))\n",
    "\n",
    "        return 100 * torch.mean(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_images(directory, extensions={\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\", \".tiff\", \".webp\"}):\n",
    "    image_count = 0\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        image_count += sum(1 for file in files if os.path.splitext(file)[1].lower() in extensions)\n",
    "    \n",
    "    return image_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image files: 11579.0\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "directory_path = \"/home/gkmo/workspace/data/KITTI_eigen_split/train/rgb\"  # Change this to the folder you want to scan\n",
    "print(f\"Total image files: {count_images(directory_path)/2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image files: 652\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "directory_path = \"/home/gkmo/workspace/data/KITTI_eigen_split/test/output_rgb\"  # Change this to the folder you want to scan\n",
    "print(f\"Total image files: {count_images(directory_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def organize_images(train_root, output_rgb=\"output_rgb\", output_depth=\"output_depth\"):\n",
    "    # Paths for output folders\n",
    "    rgb_output_dir = os.path.join(train_root, output_rgb)\n",
    "    depth_output_dir = os.path.join(train_root, output_depth)\n",
    "    os.makedirs(rgb_output_dir, exist_ok=True)\n",
    "    os.makedirs(depth_output_dir, exist_ok=True)\n",
    "\n",
    "    skipped_images = []  # List to store skipped images\n",
    "\n",
    "    # Traverse all date/sequence folders\n",
    "    for root, _, files in os.walk(train_root):\n",
    "        if \"image_02/data\" in root:\n",
    "            for file in files:\n",
    "                if file.endswith(\".png\"):\n",
    "                    # Construct the corresponding depth path\n",
    "                    depth_root = root.replace(\"image_02/data\", \"proj_depth/groundtruth/image_02\")\n",
    "                    src_depth = os.path.join(depth_root, file)\n",
    "\n",
    "                    # Check if the depth image exists\n",
    "                    if os.path.exists(src_depth):\n",
    "                        # Get the relative path (excluding 'train_root')\n",
    "                        relative_path = os.path.relpath(root, train_root).replace(os.sep, \"_\")\n",
    "                        new_filename = f\"{relative_path}_{file}\"  # e.g., \"date1_sequence1_image_02_data_000001.png\"\n",
    "\n",
    "                        # Copy RGB image\n",
    "                        src_rgb = os.path.join(root, file)\n",
    "                        dst_rgb = os.path.join(rgb_output_dir, new_filename)\n",
    "                        shutil.copy2(src_rgb, dst_rgb)\n",
    "\n",
    "                        # Copy Depth image\n",
    "                        dst_depth = os.path.join(depth_output_dir, new_filename)\n",
    "                        shutil.copy2(src_depth, dst_depth)\n",
    "                    else:\n",
    "                        # If depth image is missing, log the skipped file\n",
    "                        skipped_images.append(os.path.join(root, file))\n",
    "\n",
    "    print(f\"Images copied into {rgb_output_dir} and {depth_output_dir}, ensuring all pairs match.\")\n",
    "\n",
    "    # Print skipped images\n",
    "    if skipped_images:\n",
    "        print(\"\\nSkipped the following RGB images due to missing depth maps:\")\n",
    "        for img in skipped_images:\n",
    "            print(img)\n",
    "    else:\n",
    "        print(\"\\nAll RGB images had corresponding depth maps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images copied into /home/gkmo/Downloads/archive/train/output_rgb and /home/gkmo/Downloads/archive/train/output_depth, ensuring all pairs match.\n",
      "\n",
      "All RGB images had corresponding depth maps.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "train_directory = \"/home/gkmo/Downloads/archive/train\"  # Change this to your actual train folder\n",
    "organize_images(train_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
